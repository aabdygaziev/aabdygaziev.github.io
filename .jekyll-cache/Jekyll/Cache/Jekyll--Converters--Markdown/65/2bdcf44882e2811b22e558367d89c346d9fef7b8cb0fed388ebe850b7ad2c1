I"Ÿl<hr />

<p>The problem: MNIST handwritten digit classification
MNIST data-set is classic deep learning problem. Itâ€™s a collection of handwritten digits from 0 to 9.</p>

<p><img src="/images/Keras_image/iu.png" alt="png" /></p>

<p>Keras is simple and powerfull deep learning library for Python. You can learn more by reading the <a href="https://keras.io/getting_started/intro_to_keras_for_engineers/">documentation</a>.</p>

<p><img src="/images/Keras_image/iu-2.png" alt="png" /></p>

<p>Letâ€™s start!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">"ignore"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="data-set">Data set</h2>

<p>Uploading the data set. You can download it from here: http://pjreddie.com/projects/mnist-in-csv/</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># let's upload train data
</span><span class="n">train_data_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">'data/mnist/mnist_train.csv'</span><span class="p">,</span><span class="s">'r'</span><span class="p">)</span>
<span class="n">train_data_list</span> <span class="o">=</span> <span class="n">train_data_file</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="n">train_data_file</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># # let's upload test data
</span><span class="n">test_data_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">'data/mnist/mnist_test.csv'</span><span class="p">,</span><span class="s">'r'</span><span class="p">)</span>
<span class="n">test_data_list</span> <span class="o">=</span> <span class="n">test_data_file</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="n">test_data_file</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'Number of training examples: '</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data_list</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Number of test examples: '</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data_list</span><span class="p">))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Number of training examples:  60000
Number of test examples:  10000
</code></pre></div></div>

<h2 id="data-preparation">Data Preparation</h2>

<p>Letâ€™s split labels and features into separate data sets.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># y - targets
# X - features
</span><span class="n">y_train</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data_list</span><span class="p">)):</span>
    <span class="n">y_train</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_data_list</span><span class="p">[</span><span class="n">record</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">train_data_list</span><span class="p">[</span><span class="n">record</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">','</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>

<span class="n">y_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data_list</span><span class="p">)):</span>
    <span class="n">y_test</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_data_list</span><span class="p">[</span><span class="n">record</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">test_data_list</span><span class="p">[</span><span class="n">record</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">','</span><span class="p">)</span>
    <span class="n">X_test</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># converting to numpy array
</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asfarray</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asfarray</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asfarray</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asfarray</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_images</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>

<span class="c1"># check the shapes
</span><span class="k">print</span><span class="p">(</span><span class="s">'y_train shape:'</span><span class="p">,</span><span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'X_train shape: '</span><span class="p">,</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'y_test shape:'</span><span class="p">,</span><span class="n">y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'X_test shape: '</span><span class="p">,</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>y_train shape: (60000,)
X_train shape:  (60000, 784)
y_test shape: (10000,)
X_test shape:  (10000, 784)
</code></pre></div></div>

<p>Then we normalize our data. Instead of having pixel values from [0-255] we center them from [-0.5 to 0.5]. Usually smaller and centered values are better to train.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Normalize the images.
</span><span class="n">train_images</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_images</span> <span class="o">/</span> <span class="mi">255</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_images</span> <span class="o">/</span> <span class="mi">255</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
</code></pre></div></div>

<h2 id="building-the-model">Building the Model</h2>

<p>Keras allows to build <strong>Sequential</strong> and <strong>Functional</strong> models. Sequential model is the simplest model where layers of neurons stacked and fuly connected. Functional model is more customizable. Here weâ€™re going to build Sequential model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># instantiate model
</span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>

<p>First and second layers, each have 64 nodes with <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">ReLU</a> activation function. Output layer has 10 nodes, one for each label with a <a href="https://en.wikipedia.org/wiki/Softmax_function">Softmax</a> activation function.</p>

<h2 id="compile-the-model">Compile the Model</h2>

<p>Now we need to compile our model before we start training. We need to define 3 main key factors:</p>
<ul>
  <li>Optimizer - gradient descent</li>
  <li>Loss function</li>
  <li>Metric</li>
</ul>

<p>Keras has many <a href="https://keras.io/api/optimizers/">optimizers</a>. In our model we will use <a href="https://arxiv.org/abs/1412.6980"><strong>Adam</strong> - gradient based optimization</a>. 
For the Loss function <strong>Cross-Entropy Loss</strong>. To learn more about loss functions, go to Keras documentation: <a href="https://keras.io/api/losses/">Kerasâ€™ loss functions</a>. As for the metric weâ€™ll use <strong>accuracy</strong>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">]</span>
<span class="p">)</span>
</code></pre></div></div>

<h2 id="training-the-model">Training the Model</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>

<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">train_images</span><span class="p">,</span> <span class="c1">#train data-set
</span>    <span class="n">y</span><span class="o">=</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="c1">#labels
</span>    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/5
60000/60000 [==============================] - 4s 72us/step - loss: 0.0946 - accuracy: 0.9700
Epoch 2/5
60000/60000 [==============================] - 4s 69us/step - loss: 0.0827 - accuracy: 0.9734
Epoch 3/5
60000/60000 [==============================] - 4s 69us/step - loss: 0.0774 - accuracy: 0.9752
Epoch 4/5
60000/60000 [==============================] - 4s 68us/step - loss: 0.0691 - accuracy: 0.9778
Epoch 5/5
60000/60000 [==============================] - 4s 69us/step - loss: 0.0645 - accuracy: 0.9790





&lt;keras.callbacks.callbacks.History at 0x7f7ebce536d0&gt;
</code></pre></div></div>

<p>Great! After 5 epochs of training we achieved 0.9790 accuracy. It may look promising but it doesnâ€™t tell us much. We need to test the model.</p>

<h2 id="testing-the-model">Testing the Model</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span>
  <span class="n">test_images</span><span class="p">,</span>
  <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>10000/10000 [==============================] - 0s 30us/step





[0.088274097120855, 0.9717000126838684]
</code></pre></div></div>

<p>After testing, our modelâ€™s loss is 0.088 and accuracy is 0.9717. Not bad at all, slightly lower accuracy than on training data.</p>

<h2 id="experiment-with-model">Experiment with Model</h2>

<p>Letâ€™s try out different parameters to compare the results.</p>

<h3 id="number-of-epochs">Number of epochs?</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">]</span>
<span class="p">)</span>


<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>

<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">train_images</span><span class="p">,</span> <span class="c1">#train data-set
</span>    <span class="n">y</span><span class="o">=</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="c1">#labels
</span>    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'test accuracy: '</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span>
  <span class="n">test_images</span><span class="p">,</span>
  <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="p">)</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/10
60000/60000 [==============================] - 4s 71us/step - loss: 0.3518 - accuracy: 0.8953
Epoch 2/10
60000/60000 [==============================] - 4s 72us/step - loss: 0.1812 - accuracy: 0.9449
Epoch 3/10
60000/60000 [==============================] - 4s 70us/step - loss: 0.1415 - accuracy: 0.9566
Epoch 4/10
60000/60000 [==============================] - 4s 71us/step - loss: 0.1192 - accuracy: 0.9628
Epoch 5/10
60000/60000 [==============================] - 4s 71us/step - loss: 0.1042 - accuracy: 0.9669
Epoch 6/10
60000/60000 [==============================] - 4s 71us/step - loss: 0.0952 - accuracy: 0.9698
Epoch 7/10
60000/60000 [==============================] - 5s 75us/step - loss: 0.0848 - accuracy: 0.9731
Epoch 8/10
60000/60000 [==============================] - 5s 79us/step - loss: 0.0773 - accuracy: 0.9751
Epoch 9/10
60000/60000 [==============================] - 5s 77us/step - loss: 0.0714 - accuracy: 0.9772
Epoch 10/10
60000/60000 [==============================] - 5s 77us/step - loss: 0.0675 - accuracy: 0.9774
test accuracy: 
10000/10000 [==============================] - 0s 39us/step





[0.10760164717165753, 0.9682999849319458]
</code></pre></div></div>

<p>Looks like accuracy of the model slightly deteriorated with more iteration. May be <strong>overfitting</strong>?</p>

<h3 id="network-depth">Network Depth?</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># more layers
</span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">]</span>
<span class="p">)</span>


<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>

<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">train_images</span><span class="p">,</span> <span class="c1">#train data-set
</span>    <span class="n">y</span><span class="o">=</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="c1">#labels
</span>    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="p">)</span>


<span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span>
  <span class="n">test_images</span><span class="p">,</span>
  <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="p">)</span>

</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/5
60000/60000 [==============================] - 5s 83us/step - loss: 0.3504 - accuracy: 0.8903
Epoch 2/5
60000/60000 [==============================] - 5s 82us/step - loss: 0.1767 - accuracy: 0.9449
Epoch 3/5
60000/60000 [==============================] - 5s 87us/step - loss: 0.1434 - accuracy: 0.9550
Epoch 4/5
60000/60000 [==============================] - 5s 86us/step - loss: 0.1182 - accuracy: 0.9631
Epoch 5/5
60000/60000 [==============================] - 5s 79us/step - loss: 0.1049 - accuracy: 0.9675
10000/10000 [==============================] - 0s 34us/step





[0.12213691611355171, 0.9623000025749207]
</code></pre></div></div>

<h3 id="different-activation-sigmoid">Different Activation: Sigmoid?</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">]</span>
<span class="p">)</span>


<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>

<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">train_images</span><span class="p">,</span> <span class="c1">#train data-set
</span>    <span class="n">y</span><span class="o">=</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="c1">#labels
</span>    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'test accuracy: '</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span>
  <span class="n">test_images</span><span class="p">,</span>
  <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/5
60000/60000 [==============================] - 5s 79us/step - loss: 0.5703 - accuracy: 0.8563
Epoch 2/5
60000/60000 [==============================] - 4s 73us/step - loss: 0.2328 - accuracy: 0.9316
Epoch 3/5
60000/60000 [==============================] - 4s 74us/step - loss: 0.1740 - accuracy: 0.9487
Epoch 4/5
60000/60000 [==============================] - 4s 69us/step - loss: 0.1411 - accuracy: 0.9581
Epoch 5/5
60000/60000 [==============================] - 4s 72us/step - loss: 0.1184 - accuracy: 0.9652
test accuracy: 
10000/10000 [==============================] - 0s 35us/step





[0.13002270174250008, 0.9621000289916992]
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>You can tune your parameters and hyper-parameters of your model to achieve desired outcome. We have implemented 4 layer (input, 2 hidden and output) neural network using <a href="https://keras.io">Keras</a>, and achived 97% accuracy on train data-set, 97% on test data-set as well.</p>

<p>As you can see above, we can play with a model with different parameters and see the results. At each setting, results vary. We should always test our model, and try different parameters.</p>
:ET